{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b471cb1f-d9e6-4e2e-80e8-30e73d6433c4",
   "metadata": {},
   "source": [
    "# [2-BENCHMARK] - Phase de sélection des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef1c1-4797-4bb3-95ad-f4bedacbbf54",
   "metadata": {},
   "source": [
    "## Import des modules\n",
    "> cf. [pyproject.toml](pyproject.toml) pour connaître les librairies à installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bc098a-0e30-4a1a-a934-1e99c35bd53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8d7e8d-e5bd-409c-92c2-f6b9cca4e0d1",
   "metadata": {},
   "source": [
    "## Récupération des données dans le stockage objet AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e4700-6d17-44d2-9210-6252b1cde358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configutations S3 access and data\n",
    "load_dotenv()\n",
    "aws_access_key_id = os.getenv('aws_access_key_id')\n",
    "aws_secret_access_key = os.getenv('aws_secret_access_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15b32a9-2fd3-4c4f-9d59-923b5ec5c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific bucket data\n",
    "bucket_name = \"hotel-resa-prediction\"\n",
    "prefix = \"datasets/\"\n",
    "filename = \"processed_hotel_bookings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124230d-f400-431f-b88f-3a2827c8a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 connection\n",
    "s3 = boto3.client(\n",
    "    service_name = \"s3\",\n",
    "    region_name = \"eu-west-3\",\n",
    "    aws_access_key_id = aws_access_key_id,\n",
    "    aws_secret_access_key = aws_secret_access_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f3fdb1-5b84-42ac-8469-d6ca8d1db83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datas \n",
    "result = s3.list_objects(Bucket=bucket_name)\n",
    "for obj in result.get('Contents'):\n",
    "    if (obj[\"Key\"].startswith(prefix)) and (obj[\"Key\"].endswith(filename)):\n",
    "        data = s3.get_object(Bucket=bucket_name, Key=obj.get('Key'))\n",
    "        contents = data['Body'].read().decode(\"utf-8\")\n",
    "        data = pd.read_csv(io.StringIO(contents), low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2634c-e8cc-4c93-95b8-ff95da6dd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26340d0-ea5d-43d7-ab52-c5b6adea218d",
   "metadata": {},
   "source": [
    "## Découpe des données en train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f5564-069c-4d1e-b676-a564ab73f289",
   "metadata": {},
   "source": [
    "**Info :** Nous allons séparer les données en variable à expliquer (target) y et en variable expliquer (features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b088921-9896-4a48-9192-bd3b6929f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"is_canceled\",  axis=1)\n",
    "y = data[\"is_canceled\"]\n",
    "print(\"Features : \", X.shape)\n",
    "print(\"Target : \", y.shape) # s'assurer de n'avoir qu'une colonne ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf09654-f92c-44d9-b3f9-e0d7843d1e27",
   "metadata": {},
   "source": [
    "**Info** : Pour l'apprentissage, nous avons besoin de séparer en deux partie, un jeu d'entraînement et un jeu de test. Nous faisons le choix de découper en 70/30 soit 70 en jeu d'entraînement et 30 en jeu de test. Ici, nous faisons le choix de ne par garder de dépendance temporelle c'est la raison pour laquelle on a mélanger le jeux de données avec la méthode shuffle.\n",
    "\n",
    "> **IMPORTANT** --> stratify a été crutial pour bien balancer car à la première itération on avait des résultats qui faisait moins bien que le hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808bfdb-34d2-4004-8b50-bd270cc44772",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    shuffle=True, \n",
    "    stratify=y # IMPORTANT pour bien balancer les prédictions première itération --> courbe ROC mauvais \n",
    ")\n",
    "print(\"Features train : \", X_train.shape)\n",
    "print(\"Target train : \", y_train.shape)\n",
    "print(\"Features test : \", X_test.shape)\n",
    "print(\"Target test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d3d1e-da37-4a98-8ead-6514f103064f",
   "metadata": {},
   "source": [
    "**Info** : Pour bien valider la distribution de la variable à expliquer en fonction des features, je vérifie quand même les éléments X et y pour être sur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd0366-414d-4a19-8b33-1f65ae1e3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour voir la distribution dans y_train --> Valider le stratify\n",
    "print(\"Distribution y_train:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nPourcentages y_train:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Pour voir la distribution dans y_test --> Valider  le stratify\n",
    "print(\"\\nDistribution y_test:\")\n",
    "print(y_test.value_counts())\n",
    "print(\"\\nPourcentages y_test:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "\n",
    "# Pour voir la distribution dans le dataset complet --> Valider  le stratify\n",
    "print(\"\\nDistribution dataset complet:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nPourcentages dataset complet:\")\n",
    "print(y.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466054ac-47d1-44b7-8756-32424a56c608",
   "metadata": {},
   "source": [
    "## Préparation des pipelines de classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535af73d-e81b-4776-b1a2-7827ae68c675",
   "metadata": {},
   "source": [
    "### Etape préprocesseur\n",
    "> on utilise le OneHotEncoder pour les variables catégoriels et le StandardScaler (centré-réduit) pour les variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841cc31b-d60f-4fbf-a535-d615b337757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data = selector(dtype_include=object)\n",
    "numerical_data = selector(dtype_exclude=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47030de5-a45b-4a05-a888-5b82aa615830",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categorical = categorical_data(X)\n",
    "n_numerical = numerical_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993fa7bb-6819-4168-ad8e-125940b5a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Categorial : {len(n_categorical)}\")\n",
    "print(f\"Numerical : {len(n_numerical)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87dc30-6091-44b7-a488-ba206c9c30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_preprocessor = StandardScaler()\n",
    "categoric_preprocessor = OneHotEncoder(\n",
    "    handle_unknown='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fdc97-db51-42d6-aefe-a7504b69ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", numeric_preprocessor, n_numerical),\n",
    "        (\"Categorical\", categoric_preprocessor, n_categorical)\n",
    "    ],\n",
    "    remainder = \"passthrough\",\n",
    ")\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46362986-2f3c-4c72-9981-fd452cc2c645",
   "metadata": {},
   "source": [
    "### Définition des modèles à benchmarker\n",
    "Un premier modèle linéaire ensuite un modèle d'arbre et un modèle de random forest. l'idée est d'ajouter ce modèle au pipeline sans configuration pour faire une première sélection pour afiner plus tards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d114ee-8759-4934-b01b-461837e9a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c67e15-3973-497f-b0dd-4b0046d7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779545b6-4c52-4cfd-981d-1dd523bf8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ensemble = RandomForestClassifier() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d5bbb-0904-42be-93a8-714114e5ac89",
   "metadata": {},
   "source": [
    "### Définition des pipelines complets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614f5c1-c5c4-4322-9595-64726046d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    model_linear\n",
    ")\n",
    "linear_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a268f61-d8d5-4018-b1be-16cccc4308e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    model_tree\n",
    ")\n",
    "tree_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ff1cf-f36e-44fc-b609-c335099bcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    model_ensemble\n",
    ")\n",
    "ensemble_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e5dc1-467c-4a13-b311-e9f726e388a6",
   "metadata": {},
   "source": [
    "## Benchmark par validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5ed3a-cb56-41ef-a791-18cc0657b7dc",
   "metadata": {},
   "source": [
    "### Lancer les validations croisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f74d4e-91b2-4270-b396-3d1b5a4d1f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_linear = cross_validate(\n",
    "    linear_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    "    error_score='raise',\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "cv_linear = pd.DataFrame(cv_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be52ac6-1c8c-4040-be70-4108d25ad46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tree = cross_validate(\n",
    "    tree_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    "    error_score='raise',\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "cv_tree = pd.DataFrame(cv_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16007fe5-40b0-49a6-911d-b80a9360b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ensemble = cross_validate(\n",
    "    ensemble_pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10,\n",
    "    error_score='raise',\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "cv_ensemble = pd.DataFrame(cv_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e47dea0-d477-4488-b01f-e2465439aeec",
   "metadata": {},
   "source": [
    "### Récupération des métriques et visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a7baa-fd51-4c4c-ad3f-d4af619327be",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_scores = -cv_linear[\"test_score\"] * 100\n",
    "tree_scores = -cv_tree[\"test_score\"] * 100\n",
    "ensemble_scores = -cv_ensemble[\"test_score\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9211a-ecaa-4626-9864-04f0071f6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(cv_linear)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd9e88-b726-4fcb-b04b-d229804da174",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    indices,\n",
    "    -linear_scores,\n",
    "    color=\"#944E63\",\n",
    "    label=\"Logistic Regression model\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    indices,\n",
    "    -tree_scores,\n",
    "    color=\"#B47B84\",\n",
    "    label=\"Decision Tree model\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    indices,\n",
    "    -ensemble_scores,\n",
    "    color=\"#0C2D57\",\n",
    "    label=\"Random Forest model\"\n",
    ")\n",
    "\n",
    "plt.ylim((0,100))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"Scores\")\n",
    "_ = plt.title(\"Comparer les 3 modèles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4ecdd-015a-43ef-a2b6-fa9d5d0955fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = {\n",
    "    \"Logistic Regression\": -linear_scores.mean(),\n",
    "    \"Decision Tree Model\": -tree_scores.mean(),\n",
    "    \"Random Forest\": -ensemble_scores.mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4f457-f4b2-4044-8779-92f64f197060",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_score = max(model_scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1fe24-8524-42ce-bf8e-1e50d881b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [model for model, score in model_scores.items() if score == highest_score] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868d892-6960-421d-b5a3-268890c75107",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(best_models) == 1:\n",
    "    print(f\"Le modèle avec le plus haut accuracy score ({highest_score:.2f}%) est: {best_models[0]}\")\n",
    "else:\n",
    "    print(f\"Le modèle avec le plus haut accuracy score ({highest_score:.2f}%) sont:\")\n",
    "    for model in best_models:\n",
    "        print(f\"\\t- {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340ce7ca-557c-4aec-8539-d66930c70115",
   "metadata": {},
   "source": [
    "**Conclusions** : à première vue, on peut dire que le modèle le plus performant sur les 10 folds est le Random Forest. avec un accuracy à 88%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab4d41-793c-481a-97c1-1a362d369441",
   "metadata": {},
   "source": [
    "### Validation finale\n",
    "> L'accuracy n'est pas forcément la seule manière de vérifier la performance du modèle en classification binaire, nous allons confirmer ceci avec le score ROC-AUC pour bien valider le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83e812-0485-4d50-a90c-03b6388d1fb3",
   "metadata": {},
   "source": [
    "**Info** : Lancer l'entrainement pour avoir le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb85dc-0f16-4364-bc39-bb08ed70b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipeline.fit(X_train, y_train)\n",
    "tree_pipeline.fit(X_train, y_train)\n",
    "ensemble_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443b570-19c7-4635-989d-c0e61718fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultat pour la régression logistique : \")\n",
    "y_pred = linear_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, linear_pipeline.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45746ae-3e7d-45be-8051-088a8f5ce02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultat pour l'arbre de décision : \")\n",
    "y_pred = tree_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, tree_pipeline.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5cb97-3a0a-4309-833e-6619745997c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultat pour le random forest : \")\n",
    "y_pred = ensemble_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, ensemble_pipeline.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3134f-1cf4-426f-9e61-3b313b297520",
   "metadata": {},
   "source": [
    "les résultats montrent bien que le meilleur modèle ici est bien le random forest. Il est donc temps d'affiner les hyperparamètres de ce modèle pour essayer d'optimiser et de le rendre explicable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34172a7f-157e-45fc-85e8-c4cc7fe2d6c6",
   "metadata": {},
   "source": [
    "## Exporter le modèle sur le cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a6081f-20c6-48d9-9e1a-3cb72b842f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"models/\"\n",
    "filename_model = \"hotel_bookings_churn_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077a278-5068-4422-b5fe-4e7c22b88cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(prefix, exist_ok=True)\n",
    "    joblib.dump(ensemble_pipeline, prefix + filename_model)\n",
    "    print(f\"Modèle optimal enregistré avec succès ({best_models[0]}) sous le nom {filename_model}.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du téléversement du modèle : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c081c5-c974-4bbf-bc20-17e61a228cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(prefix + filename_model, bucket_name, prefix + filename_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03166a42-36ac-40c7-a682-187f4eeb0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    " os.chdir(prefix)\n",
    "os.remove(filename_model)\n",
    "print(\"models : \")\n",
    "print(\"- - - \" * 3)\n",
    "if len(os.listdir()) > 1:\n",
    "        for file in os.listdir():\n",
    "            print(file)\n",
    "else: \n",
    "    print(\"Vous retrouverez le modèle sur AWS S3 !\")\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e2b91-3bd3-4380-a416-bf95ce4936d8",
   "metadata": {},
   "source": [
    "-- END --"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
